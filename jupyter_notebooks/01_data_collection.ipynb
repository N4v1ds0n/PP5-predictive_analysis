{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fc9ffad",
   "metadata": {},
   "source": [
    "# **Data collection Notebook**\n",
    "\n",
    "## Contents and purpose\n",
    "\n",
    "- Import packages\n",
    "- set up directory and path structure\n",
    "- Load raw data from Kaggle and save it to repo\n",
    "- sift through the data and process/ save it respectively\n",
    "- clean data\n",
    "- create train, test and validation sets\n",
    "\n",
    "## Important files\n",
    "\n",
    "- kaggle JSON file is a personal authentication token, if this repo is forked and reproduced, it needs to be replaced by an individual file.\n",
    "\n",
    "## Expected Results\n",
    "\n",
    "- we will receive the necessary data for the subsequent notebooks\n",
    "    - a train set to train our models\n",
    "    - a test set\n",
    "    - a validation set\n",
    "- each set will have healthy and afflicted sample images\n",
    "\n",
    "## Why are we doing this\n",
    "\n",
    "These steps are common practice for the necessary preparation of data sets for machine learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d87c140",
   "metadata": {},
   "source": [
    "# Install/ Import packages necessary for this notebook\n",
    "\n",
    "- if you have created your working environment based on the requirements.txt file, you can skip the next step, as the requirements will already be satisfied. If not, you cann install the necessary packages now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3255f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.26.1 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 1)) (1.26.1)\n",
      "Requirement already satisfied: pandas==2.1.1 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: matplotlib==3.8.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 3)) (3.8.0)\n",
      "Requirement already satisfied: seaborn==0.13.2 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 4)) (0.13.2)\n",
      "Requirement already satisfied: plotly==5.17.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 5)) (5.17.0)\n",
      "Requirement already satisfied: Pillow==10.0.1 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 6)) (10.0.1)\n",
      "Requirement already satisfied: streamlit==1.40.2 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 7)) (1.40.2)\n",
      "Requirement already satisfied: joblib==1.4.2 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 8)) (1.4.2)\n",
      "Requirement already satisfied: scikit-learn==1.3.1 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 9)) (1.3.1)\n",
      "Requirement already satisfied: tensorflow-cpu==2.16.1 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 10)) (2.16.1)\n",
      "Requirement already satisfied: keras>=3.0.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 11)) (3.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from pandas==2.1.1->-r ../requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from pandas==2.1.1->-r ../requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from pandas==2.1.1->-r ../requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from matplotlib==3.8.0->-r ../requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from matplotlib==3.8.0->-r ../requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from matplotlib==3.8.0->-r ../requirements.txt (line 3)) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from matplotlib==3.8.0->-r ../requirements.txt (line 3)) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from matplotlib==3.8.0->-r ../requirements.txt (line 3)) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from matplotlib==3.8.0->-r ../requirements.txt (line 3)) (3.2.3)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from matplotlib==3.8.0->-r ../requirements.txt (line 3)) (6.5.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from plotly==5.17.0->-r ../requirements.txt (line 5)) (9.1.2)\n",
      "Requirement already satisfied: altair<6,>=4.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from streamlit==1.40.2->-r ../requirements.txt (line 7)) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from streamlit==1.40.2->-r ../requirements.txt (line 7)) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from streamlit==1.40.2->-r ../requirements.txt (line 7)) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from streamlit==1.40.2->-r ../requirements.txt (line 7)) (8.1.8)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from streamlit==1.40.2->-r ../requirements.txt (line 7)) (4.25.8)\n",
      "Requirement already satisfied: pyarrow>=7.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from streamlit==1.40.2->-r ../requirements.txt (line 7)) (20.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from streamlit==1.40.2->-r ../requirements.txt (line 7)) (2.32.4)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from streamlit==1.40.2->-r ../requirements.txt (line 7)) (13.9.4)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from streamlit==1.40.2->-r ../requirements.txt (line 7)) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from streamlit==1.40.2->-r ../requirements.txt (line 7)) (4.14.1)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from streamlit==1.40.2->-r ../requirements.txt (line 7)) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from streamlit==1.40.2->-r ../requirements.txt (line 7)) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from streamlit==1.40.2->-r ../requirements.txt (line 7)) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from streamlit==1.40.2->-r ../requirements.txt (line 7)) (6.5.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from scikit-learn==1.3.1->-r ../requirements.txt (line 9)) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from scikit-learn==1.3.1->-r ../requirements.txt (line 9)) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from tensorflow-cpu==2.16.1->-r ../requirements.txt (line 10)) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow-cpu==2.16.1->-r ../requirements.txt (line 10)) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow-cpu==2.16.1->-r ../requirements.txt (line 10)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow-cpu==2.16.1->-r ../requirements.txt (line 10)) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow-cpu==2.16.1->-r ../requirements.txt (line 10)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow-cpu==2.16.1->-r ../requirements.txt (line 10)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow-cpu==2.16.1->-r ../requirements.txt (line 10)) (3.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow-cpu==2.16.1->-r ../requirements.txt (line 10)) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow-cpu==2.16.1->-r ../requirements.txt (line 10)) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow-cpu==2.16.1->-r ../requirements.txt (line 10)) (3.4.0)\n",
      "Requirement already satisfied: setuptools in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow-cpu==2.16.1->-r ../requirements.txt (line 10)) (58.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow-cpu==2.16.1->-r ../requirements.txt (line 10)) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow-cpu==2.16.1->-r ../requirements.txt (line 10)) (3.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow-cpu==2.16.1->-r ../requirements.txt (line 10)) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow-cpu==2.16.1->-r ../requirements.txt (line 10)) (1.73.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow-cpu==2.16.1->-r ../requirements.txt (line 10)) (2.16.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow-cpu==2.16.1->-r ../requirements.txt (line 10)) (0.31.0)\n",
      "Requirement already satisfied: jinja2 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.40.2->-r ../requirements.txt (line 7)) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.40.2->-r ../requirements.txt (line 7)) (4.24.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.40.2->-r ../requirements.txt (line 7)) (1.47.0)\n",
      "Requirement already satisfied: colorama in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from click<9,>=7.0->streamlit==1.40.2->-r ../requirements.txt (line 7)) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.40.2->-r ../requirements.txt (line 7)) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.40.2->-r ../requirements.txt (line 7)) (5.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit==1.40.2->-r ../requirements.txt (line 7)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit==1.40.2->-r ../requirements.txt (line 7)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit==1.40.2->-r ../requirements.txt (line 7)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit==1.40.2->-r ../requirements.txt (line 7)) (2025.7.14)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from rich<14,>=10.14.0->streamlit==1.40.2->-r ../requirements.txt (line 7)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from rich<14,>=10.14.0->streamlit==1.40.2->-r ../requirements.txt (line 7)) (2.19.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow-cpu==2.16.1->-r ../requirements.txt (line 10)) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow-cpu==2.16.1->-r ../requirements.txt (line 10)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow-cpu==2.16.1->-r ../requirements.txt (line 10)) (3.1.3)\n",
      "Requirement already satisfied: namex in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from keras>=3.0.0->-r ../requirements.txt (line 11)) (0.1.0)\n",
      "Requirement already satisfied: optree in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from keras>=3.0.0->-r ../requirements.txt (line 11)) (0.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow-cpu==2.16.1->-r ../requirements.txt (line 10)) (0.45.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib==3.8.0->-r ../requirements.txt (line 3)) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit==1.40.2->-r ../requirements.txt (line 7)) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.40.2->-r ../requirements.txt (line 7)) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.40.2->-r ../requirements.txt (line 7)) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.40.2->-r ../requirements.txt (line 7)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.40.2->-r ../requirements.txt (line 7)) (0.26.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow-cpu==2.16.1->-r ../requirements.txt (line 10)) (8.7.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit==1.40.2->-r ../requirements.txt (line 7)) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f1c96f",
   "metadata": {},
   "source": [
    "Now you can import the packages that will be needed in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "effd5a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65bebd6",
   "metadata": {},
   "source": [
    "## Set working directory and file path architecture for notebook\n",
    "As the notebooks are set in a subfolder of this repo we need to adjust the working directory so files can be accessed properly. \n",
    "\n",
    "First we check our current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "599ab9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Projects\\\\Code-I\\\\vscode-projects\\\\PP5-predictive_analysis'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb3a592",
   "metadata": {},
   "source": [
    "Now we can change the directory to the parent folder that contains the complete repo. We will also print our new working directory so we can check everything worked out as planned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef4bedca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to: e:\\Projects\\Code-I\\vscode-projects\\PP5-predictive_analysis\n"
     ]
    }
   ],
   "source": [
    "# Only change the directory if not already at the repo root\n",
    "current_dir = os.getcwd()\n",
    "target_dir = os.path.abspath(os.path.join(current_dir, os.pardir))  # One level up\n",
    "\n",
    "# Check if we're already in the repo root\n",
    "if os.path.basename(current_dir) == 'jupyter_notebooks':\n",
    "    os.chdir(target_dir)\n",
    "    current_dir = os.getcwd()\n",
    "    print(f\"Working directory set to: {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Current working directory remains: {current_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d853810",
   "metadata": {},
   "source": [
    "# Kaggle as a data source\n",
    "\n",
    "Kaggle is a data science platform that offers a vast repository of publicly shared datasets across diverse domains such as healthcare, finance, sports, and more. These datasets are freely available for analysis, modeling, and learning, making Kaggle a popular resource for data scientists and machine learning practitioners.\n",
    "\n",
    "In this repo we will use data from Kaggle and thus it is already part of the requirements file. If you want to install it separately you can do so via pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb06e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (1.7.4.5)\n",
      "Requirement already satisfied: bleach in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from kaggle) (2025.7.14)\n",
      "Requirement already satisfied: charset-normalizer in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from kaggle) (3.4.2)\n",
      "Requirement already satisfied: idna in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from kaggle) (4.25.8)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from kaggle) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from kaggle) (58.1.0)\n",
      "Requirement already satisfied: six>=1.10 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from kaggle) (2.5.0)\n",
      "Requirement already satisfied: webencodings in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: colorama in e:\\projects\\code-i\\vscode-projects\\pp5-predictive_analysis\\.venv\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c497bf5",
   "metadata": {},
   "source": [
    "Once we have installed Kaggle we need to change the Kaggle config directory to our current working directory. We also need to need to authenticate using our kaggle.json file. (Can be obtained from the user settings in your kaggle account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8991c299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Der Befehl \"chmod\" ist entweder falsch geschrieben oder\n",
      "konnte nicht gefunden werden.\n"
     ]
    }
   ],
   "source": [
    "# change Kaggle config directory\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
    "# Set permissions for kaggle using our json file\n",
    "! chmod 600 kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83e7ed2",
   "metadata": {},
   "source": [
    "Now we can obtain our dataset for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2360cf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/codeinstitute/cherry-leaves\n",
      "License(s): unknown\n",
      "Downloading cherry-leaves.zip to inputs/datasets/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/55.0M [00:00<?, ?B/s]\n",
      "100%|██████████| 55.0M/55.0M [00:00<00:00, 2.31GB/s]\n"
     ]
    }
   ],
   "source": [
    "# Set variables to define source and destination of our kaggle dataset\n",
    "data_path = \"codeinstitute/cherry-leaves\"\n",
    "data_folder = \"inputs/datasets/raw\"\n",
    "# If our inputs folder does not exist yet, we are creating it in the next step\n",
    "os.makedirs(data_folder, exist_ok=True)   \n",
    "# Finally we download and save the dataset\n",
    "! kaggle datasets download -d {data_path} -p {data_folder}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e72a7c",
   "metadata": {},
   "source": [
    "Now that we have our raw data, we will unzip it and remove the zipfile. We will also put a new label name for the \"powdery-mildew\" set which will be \"diseased\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad8af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the dataset\n",
    "with zipfile.ZipFile(data_folder + '/cherry-leaves.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_folder)\n",
    "# Remove the zip file\n",
    "os.remove(data_folder + '/cherry-leaves.zip')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f89c8e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing existing folder 'inputs/datasets/raw\\cherry-leaves\\diseased'...\n",
      "Renamed 'powdery_mildew' → 'diseased'\n"
     ]
    }
   ],
   "source": [
    "# Rename the 'powdery_mildew' folder to 'diseased'\n",
    "dataset_path = os.path.join(data_folder, 'cherry-leaves')\n",
    "\n",
    "old_label = os.path.join(dataset_path, 'powdery_mildew')\n",
    "new_label = os.path.join(dataset_path, 'diseased')\n",
    "\n",
    "if os.path.exists(old_label):\n",
    "    if os.path.exists(new_label):\n",
    "        print(f\"Removing existing folder '{new_label}'...\")\n",
    "        shutil.rmtree(new_label)  # <-- This deletes the existing 'diseased' folder\n",
    "    os.rename(old_label, new_label)\n",
    "    print(f\"Renamed 'powdery_mildew' → 'diseased'\")\n",
    "else:\n",
    "    print(\"The folder 'powdery_mildew' does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d360e769",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "\n",
    "---\n",
    "\n",
    "## Data cleaning\n",
    "\n",
    "Check for unnecessary files and remove all excess files. A function to remove access files can be found in PP5-predictive_analysis\\src\\data_processing.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4704be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'diseased': Image files = 2104, Non-image files removed = 0\n",
      "Folder 'healthy': Image files = 2104, Non-image files removed = 0\n",
      "Folder 'test': Image files = 0, Non-image files removed = 0\n",
      "Folder 'train': Image files = 0, Non-image files removed = 0\n",
      "Folder 'validation': Image files = 0, Non-image files removed = 0\n"
     ]
    }
   ],
   "source": [
    "# First we will add the ressource file to our path to be able to load relevant functions\n",
    "sys.path.append('./src')\n",
    "# Then we load our function from the ressource file\n",
    "from data_processing import remove_non_image_files\n",
    "\n",
    "remove_non_image_files(data_dir='inputs/datasets/raw/cherry-leaves')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82df5648",
   "metadata": {},
   "source": [
    "Now that only image files remain, we should check if all images are in working order or if we have some corrupted images in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fed94af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total corrupt images removed: 0\n"
     ]
    }
   ],
   "source": [
    "from data_processing import remove_corrupt_images\n",
    "\n",
    "corrupt_images = remove_corrupt_images(\"inputs/datasets/raw/cherry-leaves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c19b8e",
   "metadata": {},
   "source": [
    "# Split data into train-, test-, and validation set\n",
    "\n",
    "For the upcoming model training, we need a train test to train our model, a validation set to adjust our model training process and a test set to test our models performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "667930ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import split_dataset, clear_splits\n",
    "\n",
    "# First we clear the old splits if they already exist (e.g. if we run this script again to change the ratios)\n",
    "# Note, that you need to reload the original dataset to be able to run this script again\n",
    "clear_splits(data_dir='inputs/datasets/raw/cherry-leaves')\n",
    "\n",
    "# Then we split the dataset into train, validation, and test sets\n",
    "split_dataset(data_dir=f\"inputs/datasets/raw/cherry-leaves\",\n",
    "                                   train_ratio=0.7,\n",
    "                                   validation_ratio=0.15,\n",
    "                                   test_ratio=0.15\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e8cef2",
   "metadata": {},
   "source": [
    "To get an overview of the size of the sets and to check if the sets are ready for the next steps we will count the data entries of the sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ba87833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1472 images in train/healthy\n",
      "There are 1472 images in train/diseased\n",
      "There are 315 images in validation/healthy\n",
      "There are 315 images in validation/diseased\n",
      "There are 317 images in test/healthy\n",
      "There are 317 images in test/diseased\n",
      "\n",
      "Total number of images: 4208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4208"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_processing import count_dataset_images\n",
    "\n",
    "\n",
    "sets = ['train', 'validation', 'test']\n",
    "labels = ['healthy', 'diseased']\n",
    "base_path = 'inputs/datasets/raw/cherry-leaves'\n",
    "\n",
    "count_dataset_images(base_path, sets, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3117103b",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "In this notebook, we performed the essential preprocessing steps to prepare our cherry leaf dataset for modeling:\n",
    "\n",
    "- Removed non-image and corrupt files to ensure data integrity.\n",
    "- Verified and cleaned the directory structure.\n",
    "- Split the dataset into **training**, **validation**, and **test** sets with user-defined ratios. Our       default will be (70%, 15%, 15%)\n",
    "\n",
    "These steps ensure that our dataset is clean, balanced, and ready for model training and evaluation.\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Now that the dataset has been cleaned and split, the next steps are focused on understanding the data and preparing it for model training so we will explore the data (EDA) and visualize the results:\n",
    "\n",
    "- **Analyze class distribution** to check for potential imbalance between categories.\n",
    "- **Visualize image samples** to assess data quality and variation within classes.\n",
    "- **Inspect image dimensions and aspect ratios** to inform resizing or preprocessing decisions.\n",
    "\n",
    "These steps will help guide decisions around model architecture, data augmentation, and normalization techniques."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
